![](https://pic2.zhimg.com/v2-957efedcac8a42b691a070aed6d9d565_b.jpg)
![](https://pic3.zhimg.com/v2-80ed8cc36bf60bd8c9db764c2d17a9ca_b.jpg)
通过查看 Nvidia 的手册，可以知道，其实 CUDNN 内部对于 LSTM 已经有了比较好的实现。
![](https://pic4.zhimg.com/v2-e50266dd4148bece6180c9fc32c27ea7_b.jpg)
下图是变长数据集上4层双向LSTM实验的效率对比。这里有些LSTM实现没有加入，这是由于接口实现不支持，比如TensorFlow cuDNNLSTM没法处理变长数据。
![](https://pic4.zhimg.com/v2-747c810430c6ad5c0a33b28b5dc7705b_b.jpg)
CuDNNLSTM is faster (it uses the GPU support) but it has less options than LSTM (dropout for example) 
tf.contrib.cudnn_rnn.CudnnLSTM currently does not support batches with sequences of different length, thus this is normally not an option to use.

https://blog.csdn.net/happytofly/article/details/80123099
![](img/cudnnLSTM/cudnnLSTM_00.png)
![](img/cudnnLSTM/cudnnLSTM_01.png)
![](img/cudnnLSTM/cudnnLSTM_02.png)
![](img/cudnnLSTM/cudnnLSTM_03.png)
![](img/cudnnLSTM/cudnnLSTM_04.png)
![](img/cudnnLSTM/cudnnLSTM_05.png)
![](img/cudnnLSTM/cudnnLSTM_06.png)
![](img/cudnnLSTM/cudnnLSTM_07.png)
![](img/cudnnLSTM/cudnnLSTM_08.png)
![](img/cudnnLSTM/cudnnLSTM_09.png)